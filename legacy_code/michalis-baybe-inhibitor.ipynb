{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Time_h          pH  Inhib_Concentrat_M  Salt_Concentrat_M  \\\n",
      "count  611.000000  611.000000          611.000000         611.000000   \n",
      "mean   135.801964    6.342062            0.006808           0.145450   \n",
      "std    201.683867    2.529080            0.014059           0.200575   \n",
      "min      0.500000    0.000000            0.000010           0.000000   \n",
      "25%     24.000000    4.000000            0.000500           0.010000   \n",
      "50%     24.000000    7.000000            0.001000           0.100000   \n",
      "75%    144.000000    7.000000            0.003000           0.100000   \n",
      "max    672.000000   10.000000            0.100000           0.600000   \n",
      "\n",
      "        Efficiency  \n",
      "count   611.000000  \n",
      "mean     26.736841  \n",
      "std     288.788317  \n",
      "min   -4834.000000  \n",
      "25%      30.000000  \n",
      "50%      58.000000  \n",
      "75%      87.950000  \n",
      "max     100.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_AA2024 = pd.read_excel('data/filtered_AA2024.xlsx')\n",
    "print(df_AA2024.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    SMILES  Time_h    pH  Inhib_Concentrat_M  \\\n",
      "0             COCCOC(=O)OCSc1nc2c(s1)cccc2    24.0   4.0               0.001   \n",
      "1             COCCOC(=O)OCSc1nc2c(s1)cccc2    24.0  10.0               0.001   \n",
      "2            Cc1ccc(c(c1)n1nc2c(n1)cccc2)O    24.0   4.0               0.001   \n",
      "3            Cc1ccc(c(c1)n1nc2c(n1)cccc2)O    24.0  10.0               0.001   \n",
      "4  Clc1ccc(cc1)CC[C@](C(C)(C)C)(Cn1cncn1)O    24.0   4.0               0.001   \n",
      "\n",
      "   Salt_Concentrat_M  Efficiency  \n",
      "0                0.1         0.0  \n",
      "1                0.1         0.0  \n",
      "2                0.1        30.0  \n",
      "3                0.1        30.0  \n",
      "4                0.1        30.0  \n"
     ]
    }
   ],
   "source": [
    "print(df_AA2024.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set targets/objectives = efficiency for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/baybe/telemetry.py:222: UserWarning: WARNING: BayBE Telemetry endpoint https://public.telemetry.baybe.p.uptimize.merckgroup.com:4317 cannot be reached. Disabling telemetry. The exception encountered was: ConnectionError, HTTPConnectionPool(host='verkehrsnachrichten.merck.de', port=80): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa2386f7fd0>: Failed to resolve 'verkehrsnachrichten.merck.de' ([Errno -2] Name or service not known)\"))\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "parameters = [\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time (h)\",\n",
    "    values=np.arange(1, 25, 1)\n",
    "    # tolerance = 0.004, assume certain experimental noise for each parameter measurement?\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values=np.arange(-1, 15.1, 0.1)\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalDiscreteParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhibitor Concentration (M)\",\n",
    "    values=np.arange(0, 0.1, 0.01), # Remove data outliers like 0.1?\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt Concentration (M)\",\n",
    "    values=np.arange(0, 2.01, 0.01),\n",
    "    # tolerance = 0.004\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Substance parameter**\n",
    "\n",
    "Instead of values, this parameter accepts data in form of a dictionary. The items correspond to pairs of labels and SMILES. SMILES are string-based representations of molecular structures. Based on these, BayBE can assign each label a set of molecular descriptors as encoding.\n",
    "\n",
    "For instance, a parameter corresponding to a choice of solvents can be initialized with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import SubstanceParameter\n",
    "\n",
    "SubstanceParameter(\n",
    "    name=\"SMILES\",\n",
    "    data={\n",
    "        # INCORPORATE TRAINING DATA FROM DATAFRAME SMILES COLUMN\n",
    "        \"Water\": \"O\",\n",
    "        \"1-Octanol\": \"CCCCCCCCO\",\n",
    "        \"Toluene\": \"CC1=CC=CC=C1\",\n",
    "    },\n",
    "    encoding=\"MORDRED\",  # Can be also RDKIT or MORGAN_FP - WHICH IS BETTER?\n",
    "    decorrelate=0.7,  # Change threshold to avoid overfitting?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculations will typically result in 500 to 1500 numbers per molecule. **To avoid detrimental effects on the surrogate model fit, we reduce the number of descriptors via decorrelation before using them.** For instance, the decorrelate option in the example above specifies that only descriptors with a correlation lower than 0.7 to any other descriptor will be kept. This usually reduces the number of descriptors to 10-50, depending on the specific items in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The encoding concept introduced above is generalized by the CustomParameter. Here, the user is expected to provide their own descriptors for the encoding.\n",
    "\n",
    "Take, for instance, a parameter that corresponds to the choice of a polymer. Polymers are not well represented by the small molecule descriptors utilized in the SubstanceParameter. \n",
    "Still, one could provide experimental measurements or common metrics used to classify polymers:\n",
    "from baybe.parameters import CustomDiscreteParameter\n",
    "\n",
    "# Create or import new dataframe containing custom descriptors\n",
    "\n",
    "descriptors = pd.DataFrame(\n",
    "    {\n",
    "        \"Glass_Transition_TempC\": [20, -71, -39],\n",
    "        \"Weight_kDalton\": [120, 32, 241],\n",
    "    },\n",
    "    index=[\"Polymer A\", \"Polymer B\", \"Polymer C\"],  # put labels in the index\n",
    ")\n",
    "\n",
    "CustomDiscreteParameter(\n",
    "    name=\"Polymer\",\n",
    "    data=descriptors,\n",
    "    decorrelate=True,  # optional, uses default correlation threshold = 0.7?\n",
    ")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **SequentialGreedyRecommender** is a powerful recommender that leverages BoTorch optimization functions to perform sequential Greedy optimization. It can be applied for discrete, continuous and hybrid sarch spaces. It is an implementation of the BoTorch optimization functions for discrete, continuous and mixed spaces. **It is important to note that this recommender performs a brute-force search when applied in hybrid search spaces, as it optimizes the continuous part of the space while exhaustively searching choices in the discrete subspace.** You can customize this behavior to only sample a certain percentage of the discrete subspace via the sample_percentage attribute and to choose different sampling strategies via the hybrid_sampler attribute. \n",
    "\n",
    "e.g.\n",
    "strategy = TwoPhaseStrategy(recommender=SequentialGreedyRecommender(hybrid_sampler=\"Farthest\", sampling_percentage=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementing fully customized surrogate models e.g. from sklearn or PyTorch, see:\n",
    "https://emdgroup.github.io/baybe/examples/Custom_Surrogates/Custom_Surrogates.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.recommenders import RandomRecommender, SequentialGreedyRecommender\n",
    "from baybe.surrogates import GaussianProcessSurrogate\n",
    "\n",
    "available_surr_models = [\n",
    "    \"GaussianProcessSurrogate\", \n",
    "    \"BayesianLinearSurrogate\",\n",
    "    \"MeanPredictionSurrogate\",\n",
    "    \"NGBoostSurrogate\",\n",
    "    \"RandomForestSurrogate\"\n",
    "]\n",
    "\n",
    "available_acq_functions = [\n",
    "    \"qPI\",  # q-Probability Of Improvement\n",
    "    \"qEI\",  # q-Expected Improvement\n",
    "    \"qUCB\", # q-upper confidence bound with beta of 1.0\n",
    "]\n",
    "\n",
    "# Defaults anyway\n",
    "SURROGATE_MODEL = GaussianProcessSurrogate()\n",
    "ACQ_FUNCTION = \"qEI\" # q-Expected Improvement, only q-fuctions are available for batch_size > 1\n",
    "\n",
    "seq_greedy_recommender = SequentialGreedyRecommender(\n",
    "        surrogate_model=SURROGATE_MODEL,\n",
    "        acquisition_function_cls=ACQ_FUNCTION,\n",
    "        hybrid_sampler=\"Farthest\", # find more details in the documentation\n",
    "        sampling_percentage=0.3, # should be relatively low\n",
    "        allow_repeated_recommendations=False,\n",
    "        allow_recommending_already_measured=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campaign Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/baybe/strategies/deprecation.py:26: DeprecationWarning: 'TwoPhaseStrategy' is deprecated and will be removed in a future version. Please use 'recommenders.TwoPhaseMetaRecommender' class instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from baybe.strategies import TwoPhaseStrategy\n",
    "from baybe import Campaign\n",
    "\n",
    "strategy = TwoPhaseStrategy(\n",
    "    initial_recommender = RandomRecommender(),  # Initial recommender\n",
    "    # Doesn't matter since I already have training data, BUT CAN BE USED FOR BENCHMARKING\n",
    "    recommender = seq_greedy_recommender,  # Bayesian model-based optimization\n",
    "    switch_after=1  # Switch to the model-based recommender after 1 batches = immediately\n",
    ")\n",
    "\n",
    "campaign = Campaign(searchspace, objective, strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recommended experiments: \n",
      "|         |   Time (h) |   pH |   Inhibitor Concentration (M) |   Salt Concentration (M) |\n",
      "|--------:|-----------:|-----:|------------------------------:|-------------------------:|\n",
      "| 4924793 |         16 |  2.5 |                          0.01 |                     0.92 |\n",
      "| 6006943 |         19 |  8   |                          0.05 |                     0.58 |\n",
      "| 6994486 |         22 |  8.8 |                          0.08 |                     0.88 |\n"
     ]
    }
   ],
   "source": [
    "new_rec = campaign.recommend(batch_size=3) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recommended experiments with measured values: \n",
      "|         |   Time (h) |   pH |   Inhibitor Concentration (M) |   Salt Concentration (M) |   efficiency |\n",
      "|--------:|-----------:|-----:|------------------------------:|-------------------------:|-------------:|\n",
      "| 4924793 |         16 |  2.5 |                          0.01 |                     0.92 |          0.1 |\n",
      "| 6006943 |         19 |  8   |                          0.05 |                     0.58 |          0.2 |\n",
      "| 6994486 |         22 |  8.8 |                          0.08 |                     0.88 |          0.3 |\n"
     ]
    }
   ],
   "source": [
    "# Get and input efficiency value from Excel table, for specific SMILES component first, \n",
    "# then for the closest values of the rest of the parameters\n",
    "\n",
    "new_rec[\"efficiency\"] = [0.1, 0.2, 0.3]\n",
    "print(\"\\n\\nRecommended experiments with measured values: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtf, why is recommending the same values as before here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recommended experiments: \n",
      "|         |   Time (h) |   pH |   Inhibitor Concentration (M) |   Salt Concentration (M) |   efficiency |\n",
      "|--------:|-----------:|-----:|------------------------------:|-------------------------:|-------------:|\n",
      "| 4924793 |         16 |  2.5 |                          0.01 |                     0.92 |          0.1 |\n",
      "| 6006943 |         19 |  8   |                          0.05 |                     0.58 |          0.2 |\n",
      "| 6994486 |         22 |  8.8 |                          0.08 |                     0.88 |          0.3 |\n"
     ]
    }
   ],
   "source": [
    "new_new_rec = campaign.recommend(batch_size=3) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "All experiments with measured values: \n",
      "|         |   Time (h) |   pH |   Inhibitor Concentration (M) |   Salt Concentration (M) |   efficiency |\n",
      "|--------:|-----------:|-----:|------------------------------:|-------------------------:|-------------:|\n",
      "| 4924793 |         16 |  2.5 |                          0.01 |                     0.92 |          0.1 |\n",
      "| 6006943 |         19 |  8   |                          0.05 |                     0.58 |          0.2 |\n",
      "| 6994486 |         22 |  8.8 |                          0.08 |                     0.88 |          0.3 |\n",
      "| 4924793 |         16 |  2.5 |                          0.01 |                     0.92 |        nan   |\n",
      "| 6006943 |         19 |  8   |                          0.05 |                     0.58 |        nan   |\n",
      "| 6994486 |         22 |  8.8 |                          0.08 |                     0.88 |        nan   |\n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([new_rec, new_new_rec]) # etc.\n",
    "print(\"\\n\\nAll experiments with measured values: \")\n",
    "print(results.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning + Initial Data INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Transfer_Learning/basic_transfer_learning.html\n",
    "\n",
    "https://emdgroup.github.io/baybe/userguide/transfer_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Backtesting/full_initial_data.html\n",
    "\n",
    "https://emdgroup.github.io/baybe/examples/Backtesting/full_lookup.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
